Перевірку на значимість роблять шляхом перевірки гіпотези $H_0$: $\chi_{\eta\xi}^2=0$, $0<\alpha<1$. З'ясувалося, що $\chi_{\eta\xi}^2$ має хі-квадрат розподіл з $(r_1-1)(r_2-1)$ степенями свободи. \\

Тоді критична область -- область великих значень, та область прийняття гіпотези:
$\chi_{\eta\xi}^2 < \chi^2((r_1-1)(r_2-1))$.

\subsection{Інформаційна міра зв'язку}

\textit{Ентропією для змінної} $\xi$ називають величину \[H_\xi = - \Sum_i p(x_i) \ln (p(x_i)) = - M \ln (p(\xi)). \]

Позначимо ймовірність, з якою приймається пара значень $(x_i, y_j)$ як $p(x_i, y_j)$, тоді \textit{ентропією для пари} $(\xi, \eta)$ називається величина \[H_{\eta\xi} = - \Sum_{i,j} p(x_i, y_j) \ln (p(x_i, y_j)).\]

\textit{Інформаційна міра зв'язку} визначається як $I_{\eta\xi} = H_{\xi} + H_{\eta} - H{\xi\eta}$. \\

\textbf{Властивості інформаційної міри зв'язку}
\begin{enumerate}
	\item $I_{\eta\xi} \ge 0$;
	\item якщо $I_{\eta\xi} = 0$ то зв'язок між $\xi$ та $\eta$ відсутній.
\end{enumerate}

Спробуємо визначити вибіркове значення. Спочатку визначимо вибіркове значення для ентропії $\eta$ та $\xi$: \[ \widehat{H}_\eta = - \Sum_i \dfrac{n_i}{n} \cdot \ln \left(\dfrac{n_i}{n}\right) \qquad \widehat{H}_\xi = - \Sum_j \dfrac{n_j}{n} \cdot \ln \left(\dfrac{n_j}{n}\right), \] де $n_i$, $n_j$ -- абсолютні частоти прийняття змінними $\eta$ і $\xi$ відповідно своїх значень. Далі, якщо $n_{ij}$ -- абсолютна частота прийняття змінними $\eta$ і $\xi$ пари відповідних значень, то
\[\widehat{H}_{\eta\xi} = - \Sum_{i,j} \dfrac{n_{ij}}{n} \cdot \ln \left(\dfrac{n_{ij}}{n}\right),\] звідки \[ \widehat{I}_{\eta\xi} = \dfrac{1}{n} \left(\Sum_{i,j} n_{ij} \cdot \ln (n_{ij}) - \Sum_i n_i \cdot \ln (n_i) - \Sum_j n_j \cdot \ln (n_j) + n \ln n\right). \]

При перевірці характеристики на значимість $H_0: \widehat{I}_{\eta\xi}=0$, $0<\alpha<1$. $\widehat{\widehat{I}}_{\eta\xi} = 2n\widehat{I}_{\eta\xi} - n_0$, де $n_0$ -- кількість нульових елементів у таблиці спряженості. \\

Виявилось, що така перетворена статистика: $\widehat{\widehat{I}}_{\eta\xi} < \chi^2((r_1-1)(r_2-1))$. \\

Оскільки ця статистика невід'ємна, то область прийняття гіпотези матиме такий вигляд $\widehat{\widehat{I}}_{\eta\xi} < \chi^2_\alpha((r_1-1)(r_2-1))$.

\section{Дисперсійний аналіз}

Нехай є деяка кількісна скалярна змінна $\eta$ та є деякий вектор якісних змінних $\xi$. \\

\textit{Дисперсійний аналіз} займається побудовою математичної моделі зв'язку між цими змінними, а також їх аналізом. \\

\textbf{Приклад}. З'ясувати вплив сорту зернових на врожай. \\

Залежна змінна -- врожайність, якісна змінна -- сорт зернових та тип міндобрив. $\eta$ -- врожайність, $\xi_1$ -- сорт зернових, $I_1$ -- всього сортів, $\xi_2$ -- тип міндобрив, $I_2$ -- всього міндобрив. \\

Позначимо $y_{ijk}$ -- врожайність $і$-го сорт зернових при застосуванні $j$-го тип міндобрив на $k$-му полі, $\alpha_i$ -- вплив на залежну змінну, $\beta_j$ -- вплив на якісну змінну. Розглянемо тепер модель врожайності \[y_{ijk}=\mu+\alpha_i+\beta_j+c_{ij}+e_{ijk},\] 

де $\mu$, $\alpha_i$, $\beta_j$, $c_{ij}$ -- невідомі параметри, $e_{ijk}$ -- помилка моделі (наприклад вплив поля), $c_{ij}$ -- вплив взаємодії $і$-ї градації першої змінної та $j$-ї градації другої змінної на врожайність зернових. \\

Ця модель лінійна по всім параметрам, тому для її розв'язку напрошується метод найменших квадратів(МНК).

\subsection{Перевірка лінійних гіпотез для регресійної моделі}

Лінійну регресійну модель в матричному вигляді запишемо так: $\vec y = X \vec \alpha + \vec e$, де $\vec y\in\RR^N$, $X\in\RR^{N\times p}$, $\vec\alpha\in\RR^p$, $\vec e\in\RR^N$. \\

Нехай ранг $X$ дорівнює $p$ (тобто матриця має повний ранг по стовпчикам), а сама оцінка знаходилась з критерію \[Q(\alpha)=\|y-X\alpha\|_2^2\to\min\] і має вигляд: \[\widehat \alpha = (X^TX)^{-1}X^Ty.\]

Розглянемо таку множину $L = \{\vec\alpha : A\vec\alpha = \vec b, \rang  A = q\}$, де $A \in \RR^{q\times p}$ (тобто матриця має повний ранг по рядкам). \\

Розглянемо оптимальну оцінку $\vec\alpha$ для лінійної моделі методом найменших квадратів при наявності лінійних обмежень $L$: \[ \widehat\alpha_L=\widehat\alpha+(X^TX)^{-1}A^T(A(X^TX)^{-1}A^T)^{-1}(b-A\widehat{\alpha}). \]

\begin{theorem}
	При справедливості гіпотези $H_0:A\vec\alpha=b$, $\rang  A=q$, $\gamma>0$ наступна статистика \[ F = \dfrac{\dfrac{Q(\widehat{\alpha}_L)-Q(\widehat{\alpha})}{q}}{\dfrac{Q(\widehat{\alpha})}{N-p}}\] має асимптотичний $F$-розподіл $F(q, N - p)$, а відповідна область прийняття гіпотези: $F < F_\gamma (q, N - p)$ , де $F_\gamma (q, N - p)$ це $100\gamma\%$ точка $F$-розподілу.
\end{theorem}

\textbf{Зауваження}. При справедливості гіпотези $H_0$: $Q(\widehat{\alpha}_L)-Q(\widehat{\alpha})=\|X\widehat{\alpha}_L-X\widehat{\alpha}\|_2^2$. \\

\textbf{Зауваження}. Розглянемо наступну гіпотезу: $H: \alpha_i = 0$, $0<\gamma<1$, тобто перевіряємо, чи суттєво відхиляється від нуля відносний вплив $і$-ої градації. Тоді статистика, побудована по умовам теореми $F_i$ називається \textit{частинною статистикою по $і$-й змінній}, а відповідний критерій, побудований на цій статистиці, для перевірки гіпотези $H$, називається \textit{частинним $F$-критерієм по $і$-й змінній}.

\subsection{Однофакторний дисперсійний аналіз}

Нехай $\eta$ -- деяка скалярна кількісна змінна, $\xi$ -- деяка якісна незалежна змінна, яка має $I$ градацій. При фіксованій $і$-й градації вважаємо, що є $J_i$ спостережень над залежною змінною, які позначимо через $y_{ij}$. Розглянемо модель \[y_{ij}= \mu + \mu_i + e_{ij}, \quad i = \overline{1,I}, \quad j = \overline{1, J}. \]

Припустимо, що помилки моделі:
\begin{enumerate}
	\item нормально розподілені $N(0,\sigma^2)$, $\sigma^2 > 0$;
	\item незалежні.
\end{enumerate}

Запишемо цю модель в матричному вигляді: $y = X \vec\mu + e$, де $X \in \RR^{N\times(I+1)}$, $\vec\mu=(\mu,\mu_1,\ldots,\mu_I)^T$, де $N = \sum_{i=1}^I J_i$ -- загальна кількість вимірів.
