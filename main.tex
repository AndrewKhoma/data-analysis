\input{univ.sty}

\lhead{Лекції з аналізу даних, 2018}

\begin{document}

Під час аналізу даних виділяються наступні етапи: отримання вхідної інформації, безпосередньо сама обробка її, аналіз та інтерпретація результатів обробки даних. \\

Головне зробити правильні висновки з результатів. \\

Значення змінних які спостерігаються можуть бути як \textit{кількісні} так і \textit{якісні}. Якісні змінні поділяють на \textit{ординальні} та \textit{номінальні}. Ординальні змінні називають \textit{порядковими}, а номінальні -- \textit{класифікаційними}. Обидва типи змінних приймають свої значення з деякої множини, елементи якої називають \textit{градаціями}. Градації, які приймає як свої значення ординальна змінна, природно \textbf{впорядковані за степенем прояву властивості}. Градації номінальної змінної такого порядку \textbf{не мають}. Серед якісних змінних виділяють \textit{категоризовані} та \textit{не категоризовані}. \\

До категоризованих змінних відносять змінні, для яких повністю визначена множина градацій та правило віднесення значення змінної, яке спостерігається, до певної градації. \\

Змінні ще поділяють на \textit{дискретні} та \textit{неперервні}.

\section{Групування даних}

$\xi$ -- скалярна змінна, яка досліджується. \\

Вибірка об'єму $n$: $x_1, x_2, \ldots, x_n$. \\

У випадку великих об'ємів вибірок виникає бажання провести деяке перетворення їх з метою стиснення даних без суттєвої втрати вибірками інформативності, а тільки згодом проводити обробку цих перетворених даних. Як правило, його застосовують при обробці спостережень над неперервними змінними, коли об'єм вибірки перевищує 50, а над дискретними змінними, коли кількість значень $m$, які вони приймають, перевищує 10. \\

Перехід до згрупованих даних:
\begin{enumerate}
    \item Визначити $x_{\min} = \Min_i (x_i)$, $x_{\max} = \Max_i (x_i)$;
    
    \item Інтервал $[x_{\min}, x_{\max}]$ розбивають на $s$ однакових під-інтервалів $[a_i, b_i)$, $i = \overline{1,s}$. Зазвичай $5 \le s \le 30$. Зазвичай $s = 1 + [\log_2 n]$ або $s = [10 \log_{10} (n)]$;
    
    \item $x_i^* = \dfrac{a_i + b_I}{2}$ -- центральна точка. \\
    
    $v_i$ -- кількість вимірів з вибірки що належать інтервалу $[a_i, b_i)$. \\
    
    $\{x_1, x_2, \ldots, x_n\} \mapsto \{x_i^*, v_i\}_{i=1}^s$ $\left( \Sum_{i=1}^s v_i = n \right)$. \\
    
    Рекомендується $v_i \ge 5$, в разі $v_i < 5$ сусідні інтервали зливаються в один.
\end{enumerate}

\textbf{Зауваження!} При проведенні групування даних зовсім не обов'язково брати під-інтервали однакової довжини. \\

$F_\xi (x) = P\{ \xi < x\}$ -- функція розподілу, $p_\xi(x)$ -- функція щільності, $\{ y_i, p_i \}_{i=1}^m$ -- полігон ймовірності, якщо $\xi$ -- дискретна випадкова величина, що набуває значення $y_i$ з ймовірністю $p_i$, $i=\overline{1,m}$. \\

Оцінка характеристик по згрупованим даним:

Емпірична (вибіркова) функція розподілу $\hat{F}_\xi (x)$ буде $\hat{F}_\xi (x) = \dfrac{1}{n} \Sum_{i: b_i \le x} v_i$. \\

Емпірична (вибіркова) функція щільності $\hat{p}_\xi (x)$ буде $\hat{p}_\xi (x) = \dfrac{v_{i(x)}}{n (b_{i(x)} - a_{i(x)}}$, де $i(x)$ -- номер під-інтервалу якому належить $x$.

\section{Моделювання змінних}

Потреба в генерації спостережень над випадковими величинами із заданими функціями розподілу. \\

Зазвичай $\xi = g(\xi_1, \xi_2, \ldots, \xi_q)$, де $\xi_1, \xi_2, \ldots, \xi_q$ -- найпростіші випадкові величини, як правило вони рівномірно розподілені на відрізку $[0, 1)$. \\

Датчик (генератор) випадкових чисел -- спеціальний пристрій, який після запиту на виході дозволяє отримати реалізацію випадкової величини із заданим законом розподілу. \\

Класи датчиків (генераторів) випадкових чисел:
\begin{itemize}
    \item \textbf{табличні} -- таблиця, заповнена реалізаціями випадковою величини із заданим законом розподілу, зазвичай досить високої якості, але вони маю обмежений об'єм. Кількість вибірок невелика. 
    
    \item \textbf{фізичні} -- деякий електронний пристрій на виході якого отримують необхідну реалізацію вибірки довільного об'єму, але кожна вибірка унікальна і неповторна.
    
    \item \textbf{програмні} -- програма, що формує потрібну реалізацію. Базуються на використанні рекурентних формул з деякою глибиною пам'яті: задаючи однакові початкові значення можна отримати однакові вибірки. Генератор періодичний, отримані числа ``псевдовипадкові''.
\end{itemize}

\section{Програмні датчики}

Генератор випадкової величини з $F(x) = U([0, 1))$. \\

\textbf{Лінійна змішана формула}:
\begin{system*}
    x_i &= \dfrac{\tilde{x}_i}{M} \\
    \tilde{x}_i &= \left( a_0 + \Sum_{j=1}^\ell a_j \tilde{x}_{i-j} \right)\text{ mod }M, i = 1, 2, \ldots
\end{system*}
$\ell \ge 1$, $a_j \ge 0$ ($j = \overline{1, \ell}$), $M > 0$, $\ell$, $a_j$ ($j = \overline{0, \ell}$), $M \in \ZZ^+$, $0 \le \tilde{x}_{\ell - j} \le M - 1$, $j = \overline{1,\ell}$. \\

\textbf{Мультиплікативний конгруентний метод}:
Лінійна змішана формула ($\ell = 1$, $a_0 = 0$).
\begin{system*}
    x_i &= \dfrac{\tilde{x}_i}{M} \\
    \tilde{x}_i &= (a_1 \tilde{x}_{i-1})\text{ mod }M, i = 1, 2, \ldots
\end{system*}
$0 \le \tilde{x}_0 \le M - 1$, $\{\tilde{x}_i\}_{i \ge 0} \in \{0, 1, \ldots, M - 1\}$. \\

Послідовність $\{\tilde{x}_i\}_{i \ge 0}$ періодична. $T_{\max}$ -- максимальний період. $T_{\max} \le M$. Вигідно взяти $M$ якомога більшим, ближчим до максимального цілого числа, наприклад найбільше просте число, що менше $\Max \text{int}$. \\

Мультиплікативний конгруентний метод не дозволяє досягти максимального теоретично можливого періоду рівного $M$.

\[ \lambda(M) = \begin{cases} 1, & M = 2 \\ 2, & M = 4 \\ p^{q - 1}(p - 1), & M = p^q, p > 2, p \in \PP, q \ge 1 \\ \text{lcm}\left(\lambda\left(p_1^{q_1}\right), \lambda(p_2^{q_2}), \ldots, \lambda(p_k^{q_k})\right), & M = p_1^{q_1} \cdot p_2^{q_2} \cdot \ldots \cdot p_k^{q_k}. \end{cases} \]

\begin{theorem}
    Максимальний період послідовність $\{\tilde{x}_i\}_{i \ge 0}$ мультиплікативного конгруентного методу $T_{\max} = \lambda(M)$. $T_{\max}$ досягається при:
    \begin{enumerate}
        \item $\text{gcd}(\tilde{x}_0, M) = 1$;
        
        \item $a_1^{\lambda(M)}\text{ mod }M = 1$, $a_1$ є первісним коренем за модулем $M$.
    \end{enumerate}
\end{theorem}

\textbf{Зауваження}. Якщо покласти $M$ рівним простому числу, то $T_{\max} = M - 1$. В залежності від розрядності комп'ютера найбільшим простим числом буде:
\begin{table}[H]
    \centering
    \begin{tabular}{cccc}
        розрядність & 16 & 32 & 64 \\
         $\max$ просте число & $2^{16} - 15$ & $2^{32} - 5$ & $2^{64} - 59$  
    \end{tabular}
\end{table}

\textbf{Змішаний конгруентний метод}: \\

Лінійна змішана формула ($\ell = 1$, $a_0 > 0$).
\begin{system*}
    x_i &= \dfrac{\tilde{x}_i}{M} \\
    \tilde{x}_i &= (a_0 + a_1 \tilde{x}_{i-1})\text{ mod }M, i = 1, 2, \ldots
\end{system*}

\begin{theorem}
    Для отримання послідовності $\{\tilde{x}_i\}_{i\ge0}$ яка досягає свого $\max$ періоду $T_{\max} = M$, необхідно:
    \begin{itemize}
        \item $\text{gcd}(a_0, M) = 1$;
        
        \item $(a_1 - 1)\text{ mod }p = 0$ для всіх $p|M$, $p \in \PP$;
        
        \item $(a_1 - 1)\text{ mod }4 = 0$, якщо $4|M$.
    \end{itemize}
\end{theorem}

\textbf{Зауваження!} Вибір параметрів змішаного конгруентного методу не є гарантією високої якості вибірки. Наприклад $a_0 = a_1 = 1$. \\

\textbf{Квадратичний конгруентний метод}:
\begin{system*}
    x_i &= \dfrac{\tilde{x}_i}{M} \\
    \tilde{x}_i &= (a_0 + a_1 \tilde{x}_{i-1} + a_2 \tilde{x}_{i-1}^2)\text{ mod }M, i = 1, 2, \ldots
\end{system*}
$T_{\max} = M$. \\

\textbf{Ускладнення лінійної змішаної формули}:
\begin{system*}
    x_i &= \dfrac{\tilde{x}_i}{M} \\
    \tilde{x}_i &= g(\tilde{x}_{i-1}, \tilde{x}_{i-2}, \ldots, \tilde{x}_{i-\ell})\text{ mod }M, i = 1, 2, \ldots
\end{system*}
$T_{\max} = M$.

\section{Моделювання дискретних випадкових величин}

Скористаємося побудованими датчиками для $U([0,1))$: $\xi$ -- дискретна випадкова величина $p_i = P\{ \xi = y_i \}$, $i = \overline{1,m}$. $\Sum_{i=1}^m p_i = 1$, отже інтервал $[0, 1)$ можна розбити на $m$ під-інтервалів 
\[ \delta_1 = [0, p_1), \Delta_2 = [p_1, p_1 + p_2), \ldots, \Delta_i = \left[\Sum_{j=1}^{i-1} p_j, \Sum_{j=1}^i p_j \right), \ldots, \Delta_m = \left[ \Sum_{j=1}^{m-1} p_j, 1 \right) \] 
Довжина інтервалу $\Delta_i$ дорівнює $p_I$ ($i = \overline{1,m}$). Отримуємо від датчика $U([0,1))$ значення $X$. Якщо $x \in \Delta_i$, то $\xi$ прийняла значення $y_i$. \\

Генерування рівномірного розподілу на $[1, m]$: $p_i = P \{ \xi = i \} = \dfrac{1}{m}$, $i = \overline{1,m}$. $x$ -- значення датчика $U([0,1))$, тоді $\xi$ набуває значення $\lfloor 1 + m x \rfloor$.

\section{Моделювання неперервних випадкових величин}

Необхідно моделювати неперервну випадкову величину $\xi$ із функцією розподілу $F(z)$. \\

Розглянемо випадок коли $F(z)$ -- строго монотонна функція. Тоді у ролі реалізації $\xi$ може виступити $F^{-1}(x)$, де $x$ -- значення датчику $U([0,1))$, а $F^{-1}(x)$ -- обернена функція розподілу до $F(z)$. Нехай $\eta$ -- випадкова величина, $F(\eta) = U([0, 1))$. Тоді $F^{-1}(\eta)$:
\[ P\{ F^{-1}(\eta) < x \} = P \{ \eta < F(x) \} = F(x) \]

\textbf{Приклад.} $\xi$ -- випадкова величина, що має показниковий закон розподілу з параметром $\lambda > 0$.

\[ F(z) = \begin{cases} 1 - e^{-\lambda z}, & z \ge 0, \\ 0, & z < 0. \end{cases} \]

$F^{-1}(y) = - \dfrac{\ln(1-y)}{\lambda}$, тобто $- \dfrac{\ln(1 - \eta)}{\lambda}$ має потрібний показниковий розподіл, де $\eta$ -- випадкова величина з розподілом $U([0,1))$. Оскільки $1 - \eta$ також має розподіл $U([0,1))$, то величина $-\dfrac{\ln \eta}{\lambda}$, $\lambda > 0$ також має показниковий розподіл. Підсумовуючи, в ролі реалізації $\xi$ може виступити$-\dfrac{\ln x}{\lambda}$, де $x$ -- випадкова величина з розподілом $U([0,1))$.

\section{Моделювання нормального розподілу з параметрами $m$ та $\sigma^2$}

\begin{theorem}
    Нехай $\eta_1$ та $\eta_2$ мають розподілу $U([0,1))$. Тоді випадкові величини
    \begin{align*}
        \xi_1 &= \sin(2 \pi \eta_1) \sqrt{-2 \ln \eta_2}, \\
        \xi_2 &= \cos(2 \pi \eta_1) \sqrt{-2 \ln \eta_2}, \\
    \end{align*}
    незалежні, нормально розподілені з параметрами $0$ та $1$.
\end{theorem}

Позначимо $x_1$, $x_2$ -- незалежні спостереження над рівномірно розподіленою величиною на інтервалі $[0, 1)$. Тоді згідно теореми можна стверджувати, що значення 
\[ m + \sigma \sin (2 \pi x_1) \sqrt{- 2 \ln x_2}, m + \sigma \cos (2 \pi x_1) \sqrt{- 2 \ln x_2} \]
є спостереженнями на незалежними нормально розподіленими випадковими величинами з параметрами $m$ та $\sigma^2$. \\

У разі необхідності моделювання випадкових величин рівномірного розподілу на інтервалі $[a, b)$ достатньо взяти вихід $x$ з датчика $U([0,1))$ та отримати реалізацію випадкової величини як $a + (b - a) x$.

\section{Попередня обробка даних}

Попередня обробка даних проводить роботу пов'язану з отриманням попередніх висновків про змінні, які спостерігаються. \\

Квантилі та процентні точки розподілу. \\

Нехай $F(x)$ -- функція розподілу випадкової величини $\xi$. \\

\textit{Квантилем рівня $q$ розподілу ($q$-квантилем розподілу) неперервної випадкової величини} $\xi$ називається таке значення $u_q$, що визначається з рівняння:
\[ F(u_q) = P \{ \xi < u_q\} = q, \quad (0 < q < 1) \]

\textit{Квантилем рівня $q$ розподілу ($q$-квантилем розподілу) дискретної випадкової величини} $\xi$ називається довільне значення $u_q$ з інтервалу $[y_{i(q)}, y_{i(q) + 1}]$, для границь якого справедливо
\[ F(y_{i(q)}) < q, F(y_{i(q) + 1}) \ge q, \quad (0 < q < 1) \]
де $\{y_i\}$ -- значення, які приймає дискретна випадкова величина $\xi$. \\

Емпіричний (вибірковий) квантиль рівня $q$ розподілу випадкової величини визначається як квантиль рівня $q$ відповідного емпіричного (вибіркового) розподілу. \\

\textit{$Q$-процентною точкою розподілу неперервної випадкової величини $\xi$} називається таке значення $w_Q$, яке є розв'язком рівняння:
\[ 1 - F(w_Q) = P \{ \xi \ge w_Q \} = Q / 100, \quad 0 < Q < 100. \]

\textit{$Q$-процентною точкою розподілу дискретної випадкової величини $\xi$} називається довільне значення $w_Q$ з інтервалу $(y_{i(Q}, y_{i(Q) + 1}]$, для границь якого справедливо
\begin{align*}
    1 - F(y_{i(Q)}) &= P \{ \xi \ge y_{i(Q)} \} > \dfrac{Q}{100} \\
    1 - F(y_{i(Q) + 1}) &= P \{ \xi \ge y_{i(Q) + 1} \} \le \dfrac{Q}{100} \\
\end{align*} 

Ці два поняття взаємно доповнюють одне одного. Для неперервного випадку для певних розподілів справджується $u_q = W_{100 (1 - q)}$, $w_Q = u_{1 - Q / 100}$. \\

\textbf{Медіана} -- це квантиль рівня 0.5, тобто $u_{0.5}$. \\

\textbf{Нижній та верхній квартилі} визначаються як $u_{0.25}$ та $u_{0.75}$ відповідно. \\

\textbf{Децилі} -- це квантилі $\{ u_{i/10} \}_{i=1}^9$. \\

\textbf{Процентилі} задаються наступним чином $\{ u_{i/100} \}_{i=1}^{99}$. \\

\textbf{Інтерквантильна широта рівня $q$} ($0 < q < 1 /2$) -- це величина яка обчислюється за формулою $(u_{1 - q} - u_q)$. \\

\textbf{Інтерквартильна} широта це інтерквантильна широта рівня $1/4$, а саме $(u_{0.75} - u_{0.25})$. \\

\textbf{Ймовірнісне відхилення $d_\xi$} визначається як половина інтерквартильної широти, тобто $d_\xi = (u_{0.75} - u_{0.25}) / 2$. \\

\textbf{Інтердецильна широта} -- це інтерквантильна широта рівня $1 / 10$, а саме $(u_{0.9} - u_{0.1})$. \\

\textbf{Інтерсекстильна широта} -- це інтерквантильна широта рівня $1 / 6$, тобто $(u_{5/6} - u_{1/6})$.

\section{Характеристики положення центра значень змінної}

Нехай обробляється вибірка об'єму $n$ спостережень $x_1, x_2, \ldots, x_n$ над скалярною змінною $\xi$. \\

\textbf{Математичне сподівання} (теоретичне середнє) обчислюється за відомою формулою для $M \xi$. Відповідне вибіркове значення має вигляд $\bar{x}(n)= \dfrac{1}{n} \Sum_{i=1}^n x_i$. \\

\textbf{Середнє геометричне $G_\xi$} визначається для випадкових величин, які з ймовірністю 1 додатні. Згідно визначення $G_\xi = \exp\{M (\ln (\xi))\}$. \\

Оцінка величини має має наступний вигляд $\hat{G}_\xi = \sqrt[n]{\Prod_{i=1}^n x_i}$. \\

\textbf{Середнє гармонічне $H_\xi$} вводиться для випадкових величин $\xi$ з позитивними значеннями наступним чином: $H_\xi = 1 / M(1 / \xi)$. Емпіричне значення середнього гармонічного має вигляд \[ \hat{H}_\xi = \dfrac{n}{\Sum_{i=1}^n \frac{1}{x_i}} \]

\textbf{Мода $x_{\text{mod}}$} для неперервної випадкової величини $\xi$ вводиться як точка максимуму функції щільності $\xi$. Для дискретного розподілу $\{ y_i, p_i \}_{i \ge 0}$ визначається як довільне значення $y_k$ яке приймається з найбільшою ймовірністю. Мода може бути не єдиною. Характеристика застосовується до унімодальних розподілів. Мода визначається для неперервної випадкової величини за її гістограмою щільності, а у дискретної -- за полігоном частот відповідно.\\

\textbf{Медіана $x_{\text{med}}$} -- це квантиль рівня $0.5$, її оцінка $\hat{x}_{\text{med}}(n)$ обчислюється на основі емпіричної функції розподілу. 

\section{Характеристики розсіювання значень змінної}

Маємо вибірку об'єму $n$ спостережень $x_1, x_2, \ldots, x_n$ над скалярною змінною $\xi$. \\

\textbf{Дисперсія $\sigma^2$} підраховується згідно формули $\sigma^2 = D\xi = M(\xi - M \xi)^2$. Незміщена оцінка $\sigma^2$ має вигляд $s^2(n) = \dfrac{1}{n-1} \Sum_{i=1}^n (x_i - \bar{x}(n))^2$. Деколи більш корисно представляти $s^2(n) = \dfrac{1}{n-1} \left(\Sum_{i=1}^n x_i^2 - n \bar{x}^2(n)\right)$. \\

\textbf{Стандартне (середнє квадратичне) відхилення $\sigma$} є коренем з дисперсії $\sigma = \sqrt{D \xi}$. $s(n) = \sqrt{\dfrac{1}{n-1} \left(\Sum_{i=1}^n x_i^2 - n \bar{x}^2(n)\right)}$. \\

\textbf{Зауваження.} Стандартне відхилення для деякої оцінки називають її \textit{стандартною похибкою}. У випадку обробки нормальної вибірки $N(m, \sigma^2)$ об'єму $n$, стандартна похибка $e_\xi$ оцінки її математичного сподівання $\bar{x}(n)$ визначається як $e_\xi = \sigma / \sqrt{n}$, а відповідне вибіркове значення як $\hat{e}_xi = s(n) / \sqrt{n}$. \\

\textbf{Коефіцієнт варіації $V_\xi$} визначається для випадкових величин у яких $M \xi \ne 0$ і підраховується як $V_\xi = \sqrt{D\xi} / M \xi \cdot 100\%$. Вибіркове значення має вигляд 
\[ \hat{V}_\xi(n) = \dfrac{s(n)}{\bar{x}(n)} \cdot 100\% = \dfrac{\sqrt{\dfrac{1}{n-1} \left(\Sum_{i=1}^n x_i^2 - n \bar{x}^2(n)\right)}}{\dfrac{1}{n} \Sum_{i=1}^n x_i} \cdot 100\% \]
\textbf{Ймовірнісне відхилення $d_\xi$} є половиною інтерквартильної широти, тобто $d_\xi = (u_{0.75} - u_{0.25}) / 2$. Емпіричне значення має вигляд $\hat{d}_\xi = (\hat{u}_{0.75} - \hat{u}_{0.25}) / 2$. \\

\textbf{Розмах (широта) вибірки} $x_1, x_2, \ldots, x_n$ спостережень над $\xi$ визначається таким чином: $\hat{R}_\xi(n) = x_{\max}(n) - x_{\min}(n)$, де $x_{\max}(n)$, $x_{\min}(n)$ -- найбільший та найменший значення в вибірці відповідно. \\

\textbf{Інтервал концентрації розподілу} випадкової величини $\xi$ має такий вигляд: $(M \xi - 3 \sqrt{D \xi}, M \xi + 3 \sqrt{D \xi})$. Вибірковий аналог має вигляд $(\bar{x}(n) - 3 s(n), \bar{x}(n) + 3 s(n))$.

\section{Аналіз скошеності та гостроверхості розподілу}

Маємо вибірку об'єму $n$ спостережень $x_1, x_2, \ldots, x_n$ випадкової величини $\xi$. \\

Очевидно, що якщо розподіл $\xi$ симетричний відносно $M \xi$ то всі його непарні центральні моменти $M(\xi - M \xi)^{2k-1}$ дорівнюють нулю, якщо вони існують. В основі \textbf{коефіцієнта асиметрії} -- характеристики скошеності розподілу -- лежить третій центральний момент
\[ \beta_1 = \dfrac{M(\xi - M\xi)^3)}{(M(\xi - M \xi))^{3/2}}, \quad D \xi > 0 \]
Вибіркове значення:
\[ \hat{\beta}_1(n) = \dfrac{\dfrac{1}{n} \Sum_{i=1}^n(x_i - \bar{x}(n))^3 }{\left( \dfrac{1}{n-1} \left( \Sum_{i=1}^n x_i^2 - n \bar{x}^2(n) \right) \right)^{3/2}} \]
Для симетричних відносно $M\xi$ розподілів $\beta_1 = 0$. Якщо $\beta_1 < 0$ то розподіл скошений праворуч, якщо $\beta_1 > 0$ то розподіл скошений ліворуч. \\

При дослідженні загальної поведінки розподілу в околі моди як характеристики гостроверхості використовують \textbf{коефіцієнт ексцесу}, який базується на четвертому центральному моменті і має вигляд
\[ \beta_2 = \dfrac{M (\xi - M \xi)^4}{(M (\xi - M \xi)^2)^2} - 3, \quad D \xi > 0 \]
``$-3$'' застосовується для того. щоб коефіцієнт ексцесу нормального розподілу був рівний 0. \\

Емпіричне значення 
\[ \hat{\beta}_2(n) = \dfrac{\dfrac{1}{n} \Sum_{i=1}^n(x_i - \bar{x}(n))^4 }{\left( \dfrac{1}{n-1} \left( \Sum_{i=1}^n x_i^2 - n \bar{x}^2(n) \right) \right)^2} - 3 \]
Якщо $\beta_2 > 0$ то розподіл більш гостроверхний ніж нормальний, а якщо $\beta_2 < 0$ -- більш плоский.

\section{Характеристики випадкових векторів}

Маємо $q$-мірний випадковий вектор $\xi$. \\

Отримано $n$ спостережень $x_1, x_2, \ldots, x_n \in \RR^q$, $i=\overline{1,n}$. \\

\textit{Характеристики положення центра значень}: \textbf{математичне сподівання} представляє собою вектор, а формула обчислень лишається без змін: $M\xi$, вибіркове значення $\bar{x}(n) = \dfrac{1}{n} \Sum_{i=1}^n x_i$. \\

\textbf{Мода $x_{\text{mod}}$} у випадку вектора визначається як точка максимуму щільності $\xi$, для дискретного випадку це значення $\xi$ яке набувається з максимальною ймовірністю. \\

\textit{Характеристики розсіювання значень}: \textbf{коваріаційна матриця} визначається як $\Sum = M (\xi - M \xi) (\xi - M \xi)^T$. Емпіричний варіант: 
\[ \hat{\Sum}(n) = \dfrac{1}{n-1} \Sum_{k=1}^n (x_k - \bar{x}(n)) (x_k - \bar{x}(n))^T \] 

\textbf{Узагальнена дисперсія} визначається як визначник коваріаційної матриці: $\det \Sum$, емпіричний вигляд $\det (\hat{\Sum}(n))$. \\

\textbf{Зауваження!} Слід (trace) для квадратної матриці $A$ рівний $\text{tr} (A) = \Sum_{i=1}^n A_{i,i}$. \\

\textbf{Слід коваріаційної матриці} підраховується як $\text{tr} (\Sum)$, емпіричний вигляд $\text{tr} (\hat{\Sum}(n))$. 

\section{Перевірка стохастичності вибірки}

Для перевірки стохастичності вибірки існують такі критерії:
\begin{itemize}
    \item критерій серій на базі медіани вибірки;
    
    \item критерій зростаючих та спадаючих серій;
    
    \item критерій квадратів послідовних різниць (критерій Аббе).
\end{itemize}

Нехай $x_1, x_2, \ldots, x_n$ -- вибірка спостережень, яка досліджується. Будемо перевіряти гіпотезу про те, що ця вибірка є випадковою з рівнем значущості $\alpha$ ($0 < \alpha < 1$). \\

\textbf{Критерій серій на базі медіани вибірки}:
\begin{enumerate}
    \item Визначається оцінка медіани $\hat{x}_{\text{med}}$.
    
    \item Під кожним членом вибірки ставиться плюс якщо він строго більший за медіану і мінус навпаки. Виміри які дорівнюють медіані не враховуються.
    
    \item Для послідовності плюсів та мінусів обчислюється загальна кількість серій $\nu(n)$ та кількість членів у найдовшій серії $\tau(n)$. Серією називається під-послідовність однакових знаків.
\end{enumerate}

\textbf{Зауваження!} Вибірка матиме стохастичну природу якщо довжина найдовшої серії $\tau(n)$ на занадто довга, а загальна кількість серій $\nu(n)$ не занадто мала. \\

Гіпотеза:
\begin{system*}
    \nu(n) &> \nu_\beta(n), \\
    \tau(n) &< \tau_{1 - \beta}(n),
\end{system*}
де $\nu_\beta(n)$, $\tau_\beta(n)$ -- квантилі рівня $\beta$ статистик $\nu(n)$ та $\tau(n)$. При фіксованому $\beta$ рівень значимості $\alpha$ буде лежати у межах $\beta < \alpha < 2 \beta - \beta^2$. Якщо порушується один критерій гіпотеза відхиляється. \\

\textbf{Критерій зростаючих та спадаючих серій}: критерій чутливий не тільки до монотонних даних, але й циклічних.
\begin{enumerate}
    \item Замінити підряд розташовані значення одним представником.
    
    \item Під членом вибірки ставиться плюс або мінус в залежності від того, чи наступний член строго більший або строго менший за даний відповідно.
    
    \item Обчислюємо аналогічні статистики $\nu(n)$ та $\tau(n)$ як і в попередньому критерії.
\end{enumerate}

Гіпотеза:
\begin{system*}
    \nu(n) &> \nu_\beta(n), \\
    \tau(n) &< \tau_{1 - \beta}(n),
\end{system*}

Рівень значущості $\alpha$ лежить в тих же межах $\beta < \alpha < 2 \beta - \beta^2$. \\

\textbf{Критерій квадратів послідовних різниць (критерій Аббе)} -- \textit{викорситовується при роботі з нормальними вибірками}. \\

У ролі альтернативи при перевірці нашої гіпотези тут може витсупати наявність систематичного зміщення у вибірці. \\

Порахуємо наступну статистику:
\[ \gamma(n) = \dfrac{\Sum_{i=1}^{n-1} (x_{i+1} - x_i)^2}{2 \left(\Sum_{i=1}^n x_i^2 - n \bar{x}^2(n)\right)} \]

Гіпотеза приймається якщо $\gamma(n) > \gamma_\alpha(n)$, де для $n \le 60$ існують табличні значення квантиля, або ж для $n > 60$: 
\[ \gamma_\alpha(n) = 1 + \dfrac{u_\alpha}{\sqrt{n + (1 + u_\alpha^2)/2}}, \] де $u_\alpha$ -- квантиль рівня $\alpha$ для $N(0, 1)$. 

\section{Рангові критерії однорідності}

Розглянемо випадкові величини $\xi_1, \xi_2, \ldots, \xi_k$ з функціями розподілу $F_1(x), F_2(x), \ldots, F_k(x)$. На їх основі сформуємо об'єднану вибірку $\nu_1, \nu_2, \ldots, \nu_n$, а для кожної змінної $\xi_i$ отримаємо незалежні спостереження $x_1^{(i)}, x_2^{(i)}, \ldots, x_{n_i}^{(i)}$, $i = \overline{1,k}$. Тоді сформована вибірка буде об'ємом $n = \Sum_{i=1}^k n_i$. Для спрощення вважаємо, що всі виміри $\nu_i$, $i=\overline{1,n}$ різні. Розташувавши ці значення у порядку зростання, отримаємо \textit{варіаційний ряд} $\nu_{(1)}, \nu_{(2)}, \ldots, \nu_{(n)}$. Члени варіаційного ряду називають порядковими статистиками. \\

\textit{Рангом} спостереження $\nu_i$ ($i = \overline{1,n}$) називається його порядковий номер у побудованому варіаційному ряді, позначається $R_{i,n}$ -- ранг спостереження $\nu_i$ ($i = \overline{1,n}$). \\

\textbf{Статистика для лінійного рангового критерію}: \[ K_i = \Sum_{j = N_i - n_i + 1}^{N_i} \phi(R_{j,n}), \quad N_i = \Sum_{j=1}^i n_j, \quad i = \overline{1,k} \]

$K_i$ -- статистика по спостереження над $\xi_i$, $\phi(R_{i,n})$ -- мітка. \\

Потрібно перевірити гіпотезу $H_0: F_1(x) = F_2(x) = \ldots = F_k(x)$, $\forall x$ з рівнем значимості $\alpha$ ($0 < \alpha < 1$). Хочемо переконатись зо всі випадкові величини однаково розподілені.

\textbf{Випадок двох вибірок}: гіпотеза $H_0: F_1(x) = F_2(x)$, $\forall x$ з рівнем значимості $\alpha$ ($0 < \alpha < 1$). Альтернативні гіпотези:
\begin{align*}
    H_{11}: & F_1(x) = F_2(x - \Delta), \forall x, (\Delta \ne 0) \\
    H_{12}: & F_1(x) = F_2(x - \Delta), \forall x, (\Delta > 0) \\
    H_{13}: & F_1(x) = F_2(x - \Delta), \forall x, (\Delta < 0)
\end{align*}
Всі критерії розглядаються над першою змінною $\xi_1$.

\textbf{Критерій нормальних міток (Фішера)} \\

$C = \Sum_{i=1}^{n_1} M(R_{i, n}, n)$, де $M(m, n)$ -- математичне сподівання $m$-ої порядкової статистики вибірки довжини $n = n_1 + n_2$ нормально розподіленої величини з параметрами $0$ та $1$. 

\section{Додаток. Характеристики порядкових статистик}

Нехай $\xi$ -- випадкова величина, що є нормально розподіленою з параметрами $0$ та $1$ з функцією розподілу $\Phi(x)$ та функцією щільності $p(x)$. По вибірці $x_1, x_2, \ldots, x_n$ незалежних спостережень над $\xi$ побудуємо варіаційний ряд $x_{(1)}, x_{(2)}, \ldots, x_{(n)}$. \\

Для обчислення математичного сподівання $m$-ої порядкової статистики $x_{(m)}$ можна застосувати наступну формулу:
\[ M x_{(m)} = \Phi^{-1}(\alpha_m) - \dfrac{\beta_m}{2} \dfrac{p'(\alpha_m)}{p^2(\alpha_m)} + \dfrac{\gamma_m (2 (p'(\alpha_m))^2 - p''(\alpha_m))}{6(p'(\alpha_m))^3} + O \left(\dfrac{m}{n^4}\right), \]
де $\alpha_m = \dfrac{m}{n + 1}$, $\beta_m = \dfrac{m(n-m+1)}{(n+1)^2(n+2)}$, $\gamma_m = \dfrac{2m(n-2m+1)(n-m+1)}{(n+1)^3(n+2)(n+3)}$. \\

Або ж більш грубе наближення $M x_m \approx \Phi^{-1}(\alpha_m)$. $\Phi^{-1}(\alpha)$, $\alpha\in (0, 1)$. Якщо $\alpha \in (0, 0.5)$, то $\Phi^{-1}(\alpha) = - \Phi^{-1}(1 - \alpha)$. Якщо ж $\alpha \in [0.5, 1)$, то \[ \Phi^{-1}(\alpha) = \tau - \dfrac{a_0 + a_1\tau + a_2\tau^2}{1 + b_1\tau + b_2\tau^2 + b_3\tau^3} + \epsilon, \quad |\epsilon| < 4.5 \cdot 10^{-4}, \] $\tau = \sqrt{-2\ln(1-\alpha)}$, $a_0 = 2.515517$, $a_1 = 0.802853$, $a_2 = 0.010328$, $b_1 = 1.432788$, $b_2 = 0.189269$, $b_3 = 0.001308$. \\

Статистика $C$ має наступні характеристики при справедливості нульової гіпотези:



\end{document}
